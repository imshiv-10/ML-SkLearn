{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl0WT/XTddcdqNUM+PV5e/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imshiv-10/ML-SkLearn/blob/main/Gradient_Boosting(GBMs)_with_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting with XGBoost\n",
        "\n",
        "Gradient Boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. XGBoost is an implementation of gradient boosting that is designed for speed and performance. It stands for Extreme Gradient Boosting and it's an optimized version of gradient boosting algorithm which is highly efficient and scalable. XGBoost uses parallel processing, regularization, and early stopping to prevent overfitting, which often results in higher accuracy and faster training times compared to other gradient boosting libraries."
      ],
      "metadata": {
        "id": "TNRNEWl4Oii6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "+ Downloading a real-world dataset from a Kaggle competition\n",
        "+ Performing feature engineering and prepare the dataset for training\n",
        "+ Training and interpreting a gradient boosting model using XGBoost\n",
        "+ Training with KFold cross validation and ensembling results\n",
        "+ Configuring the gradient boosting model and tuning hyperparamters"
      ],
      "metadata": {
        "id": "CYukFbqGOW_A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gih6cEb2OEC-"
      },
      "outputs": [],
      "source": [
        "# Lets importing the required packages here \n",
        "# for preparing intial stage required packages are here...\n",
        "import numpy as np # loading the numpy module for performing the numerical operations on data\n",
        "import pandas as pd # loading pandas module to manage and pre-processing the data\n",
        "import matplotlib # loading the matplotlib module for visual perpose\n",
        "import matplotlib.pyplot as plt # ``\n",
        "import seaborn as sns # ``\n",
        "import sklearn # loading scikit-learn module for statistical pre-processing the data\n",
        "import xgboost # loading xgbm module for solving the future predictions on top of existing models at Xtreme level\n",
        "import lightgbm \n",
        "!pip install opendatasets --upgrade --quiet\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfgqFiJSRN4p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}